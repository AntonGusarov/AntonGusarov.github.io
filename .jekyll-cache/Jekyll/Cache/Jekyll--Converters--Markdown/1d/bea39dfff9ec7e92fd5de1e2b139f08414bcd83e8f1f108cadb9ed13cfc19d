I"D<p>Any computational model – no matter if this is the machine learning model or numerical solution of differential equations – must go through the <strong>validation</strong> procedure. It is needed to determine the extent to which model’s outcomes fit the real process and determine the range of validity of the model and its capability to reproduce a physical process of interest with an acceptable accuracy.</p>

<p>In [1], seven properties are proposed validation metrics ideally should have. These properties form a general framework for the development of new metrics depending on the subject area and modeling goals. In particular, any metric must possess the metric properties in the mathematical sense as a measure of the residual: 
\[d(x, y) \geq 0 \]
\[d(x, y)=d(y, x)\]
\[d(x, y)+d(y, z) \geq d(x, z)\]
\[d(x, y)=0 \Leftrightarrow x=y\]</p>

<p>This post reviews the most common error measures and metrics, discusses their benefits and limitations. Having a set of error measures at hand, the next step in the development of validation metrics is to use them to evaluate the predictive (descriptive) ability of the model in the presence of <strong>experimental uncertainties</strong>. The Bayesian approach described in can be used for these purposes [2].</p>

<p>This post describes some of the measures and metrics evaluating the deviation of modelled time-series from an experimental sample. In this context, a distinction is made between the concepts of “measure of error” and “metric of error”. A measure of error is a numerical value associated with a difference with respect to a particular property of the compared time series. The error metric is a generalized numerical characteristic of the inconsistency of the compared time series and can be of a single error measure or their combination. Often, single measure of error does not give a complete description of the difference between time series in order to be used as a metric.</p>

<h1 id="1-vector-norms">1. Vector norms</h1>

<p>In cases  where observations and simulation results are discrete, i.e. have a finite dimension, vector norms are the frequently used measures.
Let \(S\left(x_{i}\right)\) means the modelling outcome as a function of some parameter \(x_i\) (e.g. time in dynamic systems) and \(\mathcal{E}\left(x_{i}\right)\) are the corresponding experimental observations.</p>

<p>Vector norms such as \(L_1\) – <strong>Manhattan distance</strong>, \(\ L_2\) – <strong>Euclidean distance</strong>, or  \(L_{\infty}\) can be used under condition that the vectors \(S\left(x_{i}\right)\) and \(\mathcal{E}\left(x_{i}\right)\) have the same dimensionaliny \(N\):</p>

<p>\[ ||S\left(x_{i}\right) - \mathcal{E}\left(x_{i}\right)||^p = \left(\frac{1}{N} \sum_{i=1}^{N} |S\left(x_{i}\right)-\mathcal{E}\left(x_{i}\right)|^{p}\right)^{1/p}, \]</p>

<p>where: \( p = 1,2, \infty \).</p>

<p>The main limitation when using vector norms as error measures is that <strong>they do not distinguish errors due to the difference in amplitude from errors due to the time delay</strong> when the shape of the measured time series is satisfactorily reproduced. However, norms are the foundation for other measures.</p>

<h1 id="2-measures-based-on-averaging">2. Measures based on averaging</h1>

<p>A simple approach is to compare the averaged characteristics of the deviations of the modelled data from the experiment.</p>

<p>For the case of \(N\) pairs of modelled values, the difference between the observed \(y_i\) and simulated \(\hat{y}_i\) values is used in the calculation of the <strong>Mean Absolute Error (MAE)</strong>:</p>

<p>\[E_{\operatorname{MAE}}=\frac{1}{N} \sum_{i=1}^{N}|y_{i}-\hat{y}_{i}|\]</p>

<p><strong>Mean Squared Error (MSE)</strong>:
\[E_{\operatorname{MSE}}=\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^2\]</p>

<p><strong>Root Mean Squared Error (RMSE)</strong> (std. deviation of the residuals):
\[E_{\operatorname{RMSE}}= \sqrt{ \frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^2 }\]</p>

<p>In many cases, the weighting can be applied so that errors occurring in individual time intervals make a greater or lesser contribution to the overall estimate. In particular, the <strong>Weighted RMSE</strong>:</p>

<p>\[E_{\operatorname{WMSE}}=\sqrt{\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y_i}\right)^{T} w_{i}\left(y_{i}-\hat{y}_{i}\right)}\]</p>

<p>The obvious drawback of measures above is their <strong>dependence on the physical units</strong> of quantities to which they are applied. This leads to the fact that such measures, defined for different output variables of a computational model and accordingly of a simulated system cannot be directly compared in view of different measuremnt units.</p>

<p>One approach to this problem is the use of <strong>relative errors</strong>, in particular, the <strong>average absolute percentage error</strong>:</p>

<p>\[E_{\operatorname{APE}}=\frac{100}{N} \sum_{i=1}^{N} \frac{|y_{i}-\hat{y_i}|}{|y_{i}|} \%\]</p>

<p>Although this measure avoids problems with different units, the relative errors of this kind are impractical if any of the observed values is zero or the measured values are generally small.</p>

<p>Aslo we can use popular in the regression analysis, the <strong>estimated std. deviation of the residual time serie</strong>:</p>

<p>\[S_{N-1} = \sqrt{\frac{\sum_{i=1}^{N}\left(R_{i}-\bar{R}\right)}{N-1}}\]</p>

<p>where \(R_{i}=y_{i}-\hat{y}_{i}\)</p>

<p><em>An obvious drawback of the error measures above that are based on avearging is their <strong>sensitivity to extreme values and outliers</strong>. Another difficulty is that we have a single number that describes the overall quality of the model “on average” without considering possible time delay with satisfactory reproduced shape of the measured time series. Thus, <strong>such simple numerical metrics should not be used in isolation</strong>.</em></p>

<h1 id="3-theil-index">3. Theil index</h1>
<p>A convenient measure that can be used for model validation is the <strong>Theil index</strong> [1]:
\[ E_{\text {Theil}}=\frac{\sqrt{\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y_i}\right)^{2}}}{\sqrt{\frac{1}{N} \sum_{i=1}^{N} y_{i}^{2}}+\sqrt{\frac{1}{N} \sum_{i=1}^{N} \hat{y}_{i}^{2}}} \]</p>

<p>This measure gives values [0,1] which is an advantage over the measures described above in terrms of the interpretability. A value of the Theil index of zero means that the model perfectly reproduces the measured real values. The value of the index equal to unity means the lack of correspondence between the measured and obtained as a result of modeling values. A value of 0.2 – 0.3 is considered as a satisfactory fit [1]. The Tail Index can be expanded to cover \(N_p\) independent series of output.</p>

<h1 id="4-correlation-and-cross-correlation">4. Correlation and cross-correlation</h1>
<p><strong>Correlation coefficient</strong> is a frequently used tool. It varies from -1 to +1, where a value of +1 means an ideal positive relationship between the sets of measurements, which means their identity in shape. A value of –1 indicates an ideal negative relationship or, in other words, that two time series are (scaled) mirror images of each other:</p>

<p>\[ \rho = \frac{\sum_{i=1}^{N}(y_i - \bar{y_i})(\hat{y_i} - \bar{\hat{y_i}})}{\sqrt{\sum_{i=1}^{N} (y_i - \bar{y_i})^2 (\hat{y_i} - \bar{\hat{y_i}})^2 }} \]</p>

<p>The development of the idea of correlation as a measure of error is <strong>cross-correlation</strong>. It is sometimes called a <em>rolling scalar product</em> in pattern recognition. It can be used to <strong>estimate the phase shift between two time series</strong>.</p>

<h1 id="5-geer-metric">5. Geer metric</h1>

<p>In [3] T. Geer proposed a measure for comparing time series that have errors due to the phase shift and amplitude errors. These errors are calculated using expressions (13) and (14), respectively. The combined error (metric) (15) is then calculated as a generalized measure of the error between two time series.</p>

<p>\[ A_{\operatorname{Geer}}=\sqrt{\frac{\Psi_{y y}}{\Psi_{g g}}}-1 \]</p>

<p>\[ P_{\operatorname{Geer}}=\frac{1}{\pi} \arccos \left(\frac{\Psi_{y \hat{y}}}{\sqrt{\Psi_{y y} \Psi_{\hat{y} \hat{y}}}}\right) \]</p>

<p>\[ E_{\operatorname{Geer}}=\sqrt{A_{\operatorname{Geer}}^{2}+P_{\operatorname{Geer}}^{2}} \]</p>

<p>where:</p>

<p>\[ \Psi_{y y}=\frac{\sum_{i=1}^{N} y_{i}^{2}}{N}, \quad \Psi_{\hat{y} \hat{y}}=\frac{\sum_{i=1}^{N} \hat{y_i}^{2}}{N}, \quad \Psi_{\hat{y} y}=\frac{\sum_{i=1}^{N} y_{i} \hat{y}_{i}}{N}  \]</p>

<p>The limitation of this measure is in the fact that the expression for \( A_{\operatorname{Geer}} \) is assymetric w.r.t. the experimental and model arguments. Separation of the considered error into phase and amplitude is advantageous when a deeper analysis of the error sources is required. However, the measure mixes all the information within a formula for \( E_{\operatorname{Geer}} \). Thus, this metric does not take into account the form of the considered time-series, which can lead to erroneous conclusions.</p>

<h1 id="6-russel-measure">6. Russel measure</h1>

<p>In [4] D. Russell proposed a set of measures for phase, amplitude, and cumulative errors for a stable numerical estimate of the difference between two time series. This metric is similar to the Gear’s metric with the exception of the amplitude error component. The latter is defined in such a way that it has approximately the same scale as the phase error, when there is a comparable in magnitude difference in amplitude between the signals. The phase and amplitude errors are then combined into a generalized error metric as it is in the Geer’s metric. The amplitude error is defined for this composite measure as:</p>

<p>\[ A_{\operatorname{Russel}} = \operatorname{sign}(\Psi_{yy} - \Psi_{\hat{y} \hat{y}}) \lg( 1+|\frac{\Psi_{y y}-\Psi_{\hat{y} \hat{y}}}{\sqrt{\Psi_{y y} \Psi_{g g}}}| )  \]</p>

<p>Despite overcoming the problem with asymmetry it was in Gear measure, this metric can also lead to erroneous results in case of a small number of measurements, which, however, is unlikely in real model scenarios.</p>

<h1 id="7-normalized-integrated-square-error-nise">7. Normalized Integrated Square Error (NISE)</h1>

<p>This error measure is used to estimate the discrepancy between two time series in the case of the repeated tests. Conceptually, it is related to cross-correlation. This measure takes into account three aspects: phase shift, amplitude error, and the difference in the shape of the compared time series.</p>

<p>This metric uses cross-correlation to find the  \(n^* \) – the  time delay between signals as a maximum of the cross-correlation function. Then one of the rows is shifted over the second one by \(n^*\) time samples to compensate for the time shift. The value \( \Psi{y \hat{y}} \) is calculated after the compensation. The expressions for calculating the phase and amplitude errors, and distortion of the waveform, respectively, are the following:</p>

<p>\[ E_{\text{phase}}=\frac{2 \Psi_{\hat{y} y}\left(n^{*}\right)-2 \Psi_{\hat{y} y}}{\Psi_{y y}+\Psi_{\hat{y} \hat{y}}} \]</p>

<p>\[ E_{\operatorname{ampl}}=\rho(n^* )-\frac{2 \Psi_{\hat{y} y}\left(n^{*}\right)}{\Psi_{y y}+\Psi_{\hat{y} \hat{y}}} \]</p>

<p>\[ E_{\text{shape}}=1-\rho\left(n^{*}\right) \]</p>

<p>Then these measures are combined into the resulting NISE metric as:</p>

<p>\[ E_{\operatorname{NISE}}=E_{\text{phase}} + E_{\operatorname{ampl}} + E_{\text{shape}}=1-\frac{2 \Psi_{\hat{y} y}}{\Psi_{y y}+\Psi_{\hat{y} \hat{y}}} \]</p>

<h1 id="8-dynamic-time-warping-dtw">8. Dynamic Time Warping (DTW)</h1>

<p>The Dynamic Timeline Transformation algorithm or DTW measures the discrepancy between time series and was first used for speech recognition problems in the 1960s. In its basic version, this technique aligns in time the local maximums and minimums of signals by compressing or expanding the time dimension in accordance with some cost (distance) function.</p>

<p>Consider the following cost function as an example (assumed that modelled and measured vectors are of the same length):</p>

<p>\[ d[i, j]=\left(y_{i}-\hat{y}_{j}\right)^{2} \]</p>

<p>Let \( w_{k}=\left(i_{k}, j_{k}\right) \) denotes the indices of ordered pairs of time samples of series \( \mathbf{y} \) and \( \mathbf{\hat{y}} \). The DWT algorithm then searches for a monotonically increasing sequence of the ordered adjacent pairs so that the cumulative cost function (the sum of the cost functions for \( k = 1,2, …, N \) is minimized. In other words, the sequence \( \left\langle w_{1}, w_{2}, \dots, w_{N}\right\rangle \) is calculated so that the cost function, taking into account the restrictions on the sequence progressing with each time step \( (0 \leq i_{k} - i_{k-1} \leq 1 \text{\ and \ } 0 \leq j_{k} - j_{k-1} \leq 1, \ k=2, 3, \ldots, N+1 )  \). Finally, the metric is calculated as the square root of the cumulative cost function.</p>

<h1 id="summary">Summary</h1>

<p>The purpose of this post was to review the most known and widely used measures and metrics for estimating the error between the discrete time samples from a computational model and the corresponding experiment. The measures considered here are summarized and briefly described in the table:</p>

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg .tg-4c16{font-weight:bold;font-size:20px;font-family:"Times New Roman", Times, serif !important;;border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-fljg{font-size:20px;font-family:"Times New Roman", Times, serif !important;;text-align:left;vertical-align:top}
.tg .tg-tlzb{font-size:20px;font-family:"Times New Roman", Times, serif !important;;border-color:inherit;text-align:left;vertical-align:top}
</style>

<table class="tg">
  <tr>
    <th class="tg-4c16">Measure/metric</th>
    <th class="tg-4c16">Description</th>
    <th class="tg-4c16">Drawbacks</th>
  </tr>
  <tr>
    <td class="tg-tlzb"><span style="font-weight:bold">1.</span> Vector norms </td>
    <td class="tg-tlzb">Functionality defined on the vector space of the considered time series.<br /></td>
    <td class="tg-tlzb">Sensitive to the phase errors.</td>
  </tr>
  <tr>
    <td class="tg-tlzb"><span style="font-weight:bold">2.</span> MAE, MSE, RMSE</td>
    <td class="tg-tlzb">Sample characteristic of the difference vector spread.</td>
    <td class="tg-tlzb">Defined in physical units of the studied values.<br />Sensitive to extreme values and outliers.</td>
  </tr>
  <tr>
    <td class="tg-tlzb"><span style="font-weight:bold">3.</span> Std. deviation of the residual time series</td>
    <td class="tg-tlzb">Sample characteristic of the difference vector spread and position.</td>
    <td class="tg-tlzb">Positive and negative values can compensate each other. <br />Sensitive to extreme values and outliers.</td>
  </tr>
  <tr>
    <td class="tg-fljg"><span style="font-weight:bold">4.</span> Theil's index </td>
    <td class="tg-fljg">Index of time series similarity.</td>
    <td class="tg-fljg">Not-invariant w.r.t. to summation.</td>
  </tr>
  <tr>
    <td class="tg-fljg"><span style="font-weight:bold">5. </span>Correlation coefficient. Cross-correlation.<br />Coefficient of determination</td>
    <td class="tg-fljg">Statistical measure of the linear relationship between two samples.</td>
    <td class="tg-fljg">Sensitive to phase shifts between signals and does not distinguish <br />errors caused by phase shifts from the amplitude errors.</td>
  </tr>
  <tr>
    <td class="tg-fljg"><span style="font-weight:bold">6.</span> Geer metric</td>
    <td class="tg-fljg">Composite measure taking into account amplitude and phase errors.</td>
    <td class="tg-fljg">Ignores similarity in shapes of compared time series, <br />asymmetry.</td>
  </tr>
  <tr>
    <td class="tg-fljg"><span style="font-weight:bold">7.</span> Russel metric</td>
    <td class="tg-fljg">Composite measure taking into account amplitude and phase errors. <br />Analogous to the Geer metric.</td>
    <td class="tg-fljg">Ignores similarity in shapes of compared time series.</td>
  </tr>
  <tr>
    <td class="tg-fljg"><span style="font-weight:bold">8. </span>Normalized Integrated Square Error (NISE)</td>
    <td class="tg-fljg">Composite measure taking into account amplitude and phase errors. <br />Takes into account similarity in shapes of the compared time-series.</td>
    <td class="tg-fljg">The value of the amplitude error component may be negative and reducing by this the overall error value.</td>
  </tr>
  <tr>
    <td class="tg-fljg"><span style="font-weight:bold">9.</span> Dynamic Time Warping (DTW)</td>
    <td class="tg-fljg">Algorithm for finding the best fit between compared time series.</td>
    <td class="tg-fljg">Tends to a non-obvious alignment due to incorrect transformation of time axes.</td>
  </tr>
</table>

<h1 id="examples">Examples</h1>

<p><img src="01_15_n1.png" alt="Markdown Monster icon" style="float: left; margin-right: 10px;" /></p>
:ET