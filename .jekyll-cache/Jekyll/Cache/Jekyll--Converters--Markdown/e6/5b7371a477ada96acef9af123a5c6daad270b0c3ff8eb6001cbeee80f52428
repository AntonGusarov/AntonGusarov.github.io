I"²<p>Today we give a little explanation of the standard concepts in machine learning: over- and under-fitting and its relation to the model complexity all united in the concept of bias-variace tradeoff.</p>

<p>In [1], seven properties are proposed validation metrics ideally should have. These properties form a general framework for the development of new metrics depending on the subject area and modeling goals. In particular, any metric must possess the metric properties in the mathematical sense as a measure of the residual: 
\[d(x, y) \geq 0 \]
\[d(x, y)=d(y, x)\]
\[d(x, y)+d(y, z) \geq d(x, z)\]
\[d(x, y)=0 \Leftrightarrow x=y\]</p>

<h1 id="1-vector-norms">1. Vector norms</h1>

:ET