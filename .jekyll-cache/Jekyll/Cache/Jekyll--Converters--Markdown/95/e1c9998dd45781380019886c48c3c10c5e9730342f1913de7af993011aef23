I"ã<p>Today consider the standard concepts in machine learning: <strong>overfitting</strong> and <strong>underfitting</strong>, its relation to the <strong>model complexity</strong> that are all integrated in the <strong>bias-variace tradeoff</strong>.</p>

<p>In [1], seven properties are proposed validation metrics ideally should have. These properties form a general framework for the development of new metrics depending on the subject area and modeling goals. In particular, any metric must possess the metric properties in the mathematical sense as a measure of the residual: 
\[d(x, y) \geq 0 \]
\[d(x, y)=d(y, x)\]
\[d(x, y)+d(y, z) \geq d(x, z)\]
\[d(x, y)=0 \Leftrightarrow x=y\]</p>

<h1 id="1-vector-norms">1. Vector norms</h1>

:ET